#!/usr/bin/env python3
"""
ç§’è¾“ è¯­éŸ³è¾“å…¥å·¥å…· - macOS
æŒ‰ä½ Option é”®è¯´è¯ï¼Œæ¾å¼€è‡ªåŠ¨è¯†åˆ«å¹¶è¾“å…¥
"""

import sherpa_onnx
import sounddevice as sd
import numpy as np
import subprocess
import threading
import os
from pynput import keyboard

# é…ç½®
MODEL_DIR = os.path.expanduser("~/Models/ASR/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17")
SAMPLE_RATE = 16000
USE_INT8 = True  # ä½¿ç”¨é‡åŒ–æ¨¡å‹ï¼Œæ›´å¿«

class ç§’è¾“Input:
    def __init__(self):
        print("æ­£åœ¨åŠ è½½ ç§’è¾“ æ¨¡å‹...")
        self.recognizer = self._create_recognizer()
        print("æ¨¡å‹åŠ è½½å®Œæˆï¼")

        self.is_recording = False
        self.audio_data = []
        self.stream = None

    def _create_recognizer(self):
        model_file = "model.int8.onnx" if USE_INT8 else "model.onnx"

        config = sherpa_onnx.OfflineRecognizerConfig(
            model_config=sherpa_onnx.OfflineModelConfig(
                sense_voice=sherpa_onnx.Offlineç§’è¾“ModelConfig(
                    model=f"{MODEL_DIR}/{model_file}",
                    language="auto",  # è‡ªåŠ¨æ£€æµ‹è¯­è¨€
                    use_itn=True,  # ä½¿ç”¨é€†æ–‡æœ¬æ­£åˆ™åŒ–
                ),
                tokens=f"{MODEL_DIR}/tokens.txt",
                num_threads=4,
                provider="cpu",
            ),
        )
        return sherpa_onnx.OfflineRecognizer(config)

    def _audio_callback(self, indata, frames, time, status):
        if self.is_recording:
            self.audio_data.append(indata.copy())

    def start_recording(self):
        if self.is_recording:
            return
        self.is_recording = True
        self.audio_data = []
        self.stream = sd.InputStream(
            samplerate=SAMPLE_RATE,
            channels=1,
            dtype=np.float32,
            callback=self._audio_callback
        )
        self.stream.start()
        print("ğŸ¤ å¼€å§‹å½•éŸ³...")

    def stop_recording(self):
        if not self.is_recording:
            return ""

        self.is_recording = False
        if self.stream:
            self.stream.stop()
            self.stream.close()
            self.stream = None

        if not self.audio_data:
            print("æ²¡æœ‰å½•åˆ°éŸ³é¢‘")
            return ""

        print("ğŸ”„ æ­£åœ¨è¯†åˆ«...")
        audio = np.concatenate(self.audio_data, axis=0).flatten()

        # åˆ›å»ºæµå¹¶è¯†åˆ«
        stream = self.recognizer.create_stream()
        stream.accept_waveform(SAMPLE_RATE, audio)
        self.recognizer.decode_stream(stream)

        text = stream.result.text.strip()
        print(f"âœ… è¯†åˆ«ç»“æœ: {text}")
        return text

    def type_text(self, text):
        """ä½¿ç”¨ AppleScript è¾“å…¥æ–‡å­—"""
        if not text:
            return
        # è½¬ä¹‰ç‰¹æ®Šå­—ç¬¦
        escaped = text.replace('\\', '\\\\').replace('"', '\\"')
        script = f'tell application "System Events" to keystroke "{escaped}"'
        subprocess.run(["osascript", "-e", script], check=True)
        print(f"âŒ¨ï¸ å·²è¾“å…¥: {text}")


def main():
    voice_input = ç§’è¾“Input()

    print("\n" + "="*50)
    print("ç§’è¾“ è¯­éŸ³è¾“å…¥å·¥å…·")
    print("="*50)
    print("æŒ‰ä½ Option(âŒ¥) é”®è¯´è¯ï¼Œæ¾å¼€è‡ªåŠ¨è¯†åˆ«å¹¶è¾“å…¥")
    print("æŒ‰ Ctrl+C é€€å‡º")
    print("="*50 + "\n")

    def on_press(key):
        if key == keyboard.Key.alt:
            voice_input.start_recording()

    def on_release(key):
        if key == keyboard.Key.alt:
            text = voice_input.stop_recording()
            if text:
                voice_input.type_text(text)

    with keyboard.Listener(on_press=on_press, on_release=on_release) as listener:
        listener.join()


if __name__ == "__main__":
    main()
